{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7mYeTyS7q1G"
      },
      "outputs": [],
      "source": [
        "# ========================\n",
        "# Google Colab: SUIM + UIEB Evaluation\n",
        "# ========================\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from google.colab import drive\n",
        "from thop import profile, clever_format\n",
        "import torchmetrics\n",
        "\n",
        "# ====== 1. MOUNT DRIVE AND ACCEPT LINKS ======\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "suim_link = input(\"Enter Google Drive link for SUIM dataset: \").strip()\n",
        "uieb_link = input(\"Enter Google Drive link for UIEB dataset: \").strip()\n",
        "\n",
        "# Convert Google Drive share link to direct download if needed\n",
        "def gdrive_download(link, dest_folder):\n",
        "    if \"drive.google.com\" in link:\n",
        "        if \"id=\" in link:\n",
        "            file_id = link.split(\"id=\")[-1]\n",
        "        elif \"/d/\" in link:\n",
        "            file_id = link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        os.system(f\"gdown --id {file_id} -O {dest_folder} --fuzzy\")\n",
        "    else:\n",
        "        print(\"Invalid Google Drive link!\")\n",
        "\n",
        "os.makedirs(\"/content/SUIM\", exist_ok=True)\n",
        "os.makedirs(\"/content/UIEB\", exist_ok=True)\n",
        "\n",
        "gdrive_download(suim_link, \"/content/SUIM.zip\")\n",
        "gdrive_download(uieb_link, \"/content/UIEB.zip\")\n",
        "\n",
        "os.system(\"unzip -q /content/SUIM.zip -d /content/SUIM\")\n",
        "os.system(\"unzip -q /content/UIEB.zip -d /content/UIEB\")\n",
        "\n",
        "# ====== 2. PLACEHOLDER MODELS ======\n",
        "class DummySegModel(nn.Module):\n",
        "    def __init__(self, name):\n",
        "        super().__init__()\n",
        "        self.name = name\n",
        "        self.conv = nn.Conv2d(3, 3, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.conv(x))\n",
        "\n",
        "# Replace with actual implementations\n",
        "models = {\n",
        "    \"FUnIEGAN+ResNet50\": DummySegModel(\"funie_resnet50\"),\n",
        "    \"DeepLab+MobileNetV2\": DummySegModel(\"deeplab_mobilenet\"),\n",
        "    \"DeepLab+TinyFUnIEGAN+PrunedMobileOne50\": DummySegModel(\"deeplab_tinyfunie_mobileone\"),\n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ====== 3. DATA LOADING (SUIM + UIEB) ======\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "def load_dataset_images(path, max_samples=20):\n",
        "    images, masks = [], []\n",
        "    img_folder = os.path.join(path, \"images\")\n",
        "    mask_folder = os.path.join(path, \"masks\")\n",
        "    for i, file in enumerate(os.listdir(img_folder)):\n",
        "        if i >= max_samples:\n",
        "            break\n",
        "        img_path = os.path.join(img_folder, file)\n",
        "        mask_path = os.path.join(mask_folder, file)\n",
        "        if os.path.exists(img_path) and os.path.exists(mask_path):\n",
        "            img = transform(Image.open(img_path).convert(\"RGB\"))\n",
        "            mask = transform(Image.open(mask_path).convert(\"L\"))\n",
        "            images.append(img)\n",
        "            masks.append(mask)\n",
        "    return torch.stack(images), torch.stack(masks)\n",
        "\n",
        "suim_imgs, suim_masks = load_dataset_images(\"/content/SUIM\")\n",
        "uieb_imgs, uieb_masks = load_dataset_images(\"/content/UIEB\")\n",
        "\n",
        "# ====== 4. METRICS ======\n",
        "miou_metric = torchmetrics.JaccardIndex(task=\"binary\", num_classes=2).to(device)\n",
        "dice_metric = torchmetrics.Dice().to(device)\n",
        "\n",
        "def evaluate_model(model, images, masks):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    # Params and GFLOPs\n",
        "    dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
        "    flops, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops, params = clever_format([flops, params], \"%.3f\")\n",
        "\n",
        "    # Latency\n",
        "    torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        _ = model(dummy_input)\n",
        "    torch.cuda.synchronize() if device == \"cuda\" else None\n",
        "    latency = (time.time() - start_time) * 1000  # ms\n",
        "\n",
        "    # Power consumption placeholder\n",
        "    power_watts = np.random.uniform(3, 7)  # mock values\n",
        "\n",
        "    # mIoU & Dice\n",
        "    preds = []\n",
        "    gts = []\n",
        "    with torch.no_grad():\n",
        "        for img, mask in zip(images, masks):\n",
        "            img = img.unsqueeze(0).to(device)\n",
        "            pred = model(img)\n",
        "            pred_bin = (pred > 0.5).float()\n",
        "            preds.append(pred_bin.cpu())\n",
        "            gts.append(mask.unsqueeze(0).cpu())\n",
        "\n",
        "    preds = torch.cat(preds).to(device)\n",
        "    gts = torch.cat(gts).to(device)\n",
        "\n",
        "    miou = miou_metric(preds, gts).item()\n",
        "    dice = dice_metric(preds, gts).item()\n",
        "\n",
        "    return params, flops, latency, power_watts, miou, dice\n",
        "\n",
        "# ====== 5. RUN EVALUATION ======\n",
        "for dataset_name, (imgs, masks) in {\n",
        "    \"SUIM\": (suim_imgs, suim_masks),\n",
        "    \"UIEB\": (uieb_imgs, uieb_masks)\n",
        "}.items():\n",
        "    print(f\"\\n=== Dataset: {dataset_name} ===\")\n",
        "    for model_name, model in models.items():\n",
        "        params, flops, latency, power, miou, dice = evaluate_model(model, imgs, masks)\n",
        "        print(f\"{model_name}: Params={params}, GFLOPs={flops}, Latency={latency:.2f} ms, Power={power:.2f} W, mIoU={miou:.4f}, Dice={dice:.4f}\")\n"
      ]
    }
  ]
}