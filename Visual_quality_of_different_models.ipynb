{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc3DCHw_9VD6"
      },
      "outputs": [],
      "source": [
        "# =======================================\n",
        "# Google Colab - SUIM Visual Quality Demo\n",
        "# =======================================\n",
        "!pip install gdown tensorflow opencv-python matplotlib --quiet\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import gdown\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Accept SUIM dataset link from user\n",
        "# ------------------------------\n",
        "drive_link = input(\"Enter Google Drive link for SUIM dataset: \").strip()\n",
        "\n",
        "# Convert share link to direct download link\n",
        "def gdrive_to_direct(link):\n",
        "    if \"drive.google.com\" in link:\n",
        "        if \"id=\" in link:\n",
        "            file_id = link.split(\"id=\")[1]\n",
        "        elif \"/d/\" in link:\n",
        "            file_id = link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        else:\n",
        "            raise ValueError(\"Invalid Google Drive link format.\")\n",
        "        return f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    else:\n",
        "        return link\n",
        "\n",
        "direct_link = gdrive_to_direct(drive_link)\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Download and extract dataset\n",
        "# ------------------------------\n",
        "output_zip = \"suim_dataset.zip\"\n",
        "gdown.download(direct_link, output_zip, quiet=False)\n",
        "\n",
        "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"suim_dataset\")\n",
        "\n",
        "image_dir = \"suim_dataset/images\"\n",
        "mask_dir = \"suim_dataset/masks\"\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Dummy models (replace with trained weights)\n",
        "# ------------------------------\n",
        "# Load pre-trained / fine-tuned models\n",
        "funie_gan = load_model(\"/path/to/FUnIEGAN_model.h5\", compile=False)\n",
        "tiny_funie_gan = load_model(\"/path/to/TinyFUnIEGAN_model.h5\", compile=False)\n",
        "mobilenet_seg = load_model(\"/path/to/MobileNetV2_segmentation_model.h5\", compile=False)\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Helper functions\n",
        "# ------------------------------\n",
        "def load_image(path, target_size=(256, 256)):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    return img\n",
        "\n",
        "def preprocess(img):\n",
        "    return img.astype(np.float32) / 255.0\n",
        "\n",
        "def postprocess(mask):\n",
        "    mask = (mask > 0.5).astype(np.uint8)\n",
        "    return mask\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Visualize outputs\n",
        "# ------------------------------\n",
        "sample_images = sorted(os.listdir(image_dir))[:5]  # first 5 samples\n",
        "for img_name in sample_images:\n",
        "    img_path = os.path.join(image_dir, img_name)\n",
        "    mask_path = os.path.join(mask_dir, img_name)\n",
        "\n",
        "    # Load\n",
        "    orig_img = load_image(img_path)\n",
        "    gt_mask = load_image(mask_path, target_size=(256, 256))[:,:,0]  # assuming single channel mask\n",
        "\n",
        "    # Enhance\n",
        "    enhanced_funie = funie_gan.predict(np.expand_dims(preprocess(orig_img), axis=0))[0]\n",
        "    enhanced_tiny_funie = tiny_funie_gan.predict(np.expand_dims(preprocess(orig_img), axis=0))[0]\n",
        "\n",
        "    # Segment\n",
        "    pred_mask_mobilenet = mobilenet_seg.predict(np.expand_dims(preprocess(orig_img), axis=0))[0]\n",
        "    pred_mask_mobilenet = postprocess(pred_mask_mobilenet[:,:,0])\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.imshow(orig_img)\n",
        "    plt.title(\"Original Image\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.imshow((enhanced_funie * 255).astype(np.uint8))\n",
        "    plt.title(\"Enhanced (FUnIE-GAN)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.imshow((enhanced_tiny_funie * 255).astype(np.uint8))\n",
        "    plt.title(\"Enhanced (Tiny FUnIE-GAN)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    plt.imshow(gt_mask, cmap=\"gray\")\n",
        "    plt.title(\"Ground Truth Mask\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.imshow(pred_mask_mobilenet, cmap=\"gray\")\n",
        "    plt.title(\"Predicted Mask (MobileNetV2)\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ]
}