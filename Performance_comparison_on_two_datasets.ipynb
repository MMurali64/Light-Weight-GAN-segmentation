{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQHUs4_Q9pyN"
      },
      "outputs": [],
      "source": [
        "# Colab-ready script\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import psutil\n",
        "import GPUtil\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "from ptflops import get_model_complexity_info\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models\n",
        "\n",
        "# ------------------------------\n",
        "# 1. Accept Google Drive links from user\n",
        "# ------------------------------\n",
        "suim_link = input(\"Enter Google Drive link for SUIM dataset: \").strip()\n",
        "uieb_link = input(\"Enter Google Drive link for UIEB dataset: \").strip()\n",
        "\n",
        "# Extract file ID from Google Drive link\n",
        "def extract_file_id(link):\n",
        "    if \"id=\" in link:\n",
        "        return link.split(\"id=\")[1]\n",
        "    elif \"/d/\" in link:\n",
        "        return link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "suim_id = extract_file_id(suim_link)\n",
        "uieb_id = extract_file_id(uieb_link)\n",
        "\n",
        "if suim_id:\n",
        "    os.system(f\"gdown --id {suim_id} -O suim.zip\")\n",
        "    os.system(\"unzip -q suim.zip -d suim_dataset\")\n",
        "else:\n",
        "    print(\"Invalid SUIM dataset link!\")\n",
        "\n",
        "if uieb_id:\n",
        "    os.system(f\"gdown --id {uieb_id} -O uieb.zip\")\n",
        "    os.system(\"unzip -q uieb.zip -d uieb_dataset\")\n",
        "else:\n",
        "    print(\"Invalid UIEB dataset link!\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Dummy Dataset Loader (Replace with actual dataset logic)\n",
        "# ------------------------------\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.img_list = os.listdir(img_dir)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_list[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.img_list[idx].replace(\".jpg\", \".png\"))\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "# Example paths (Update these to match dataset structure)\n",
        "suim_dataset = SegmentationDataset(\"suim_dataset/images\", \"suim_dataset/masks\", transform)\n",
        "uieb_dataset = SegmentationDataset(\"uieb_dataset/images\", \"uieb_dataset/masks\", transform)\n",
        "\n",
        "suim_loader = DataLoader(suim_dataset, batch_size=1, shuffle=False)\n",
        "uieb_loader = DataLoader(uieb_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Dummy Models (Replace with actual)\n",
        "# ------------------------------\n",
        "class DummySegFormer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.backbone = models.resnet18(pretrained=False)\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(torch.randn(x.size(0), 1, x.size(2), x.size(3)))\n",
        "\n",
        "# Example models\n",
        "models_dict = {\n",
        "    \"Fast-EUVP-UW-SegFormer-B0 (Proposed)\": DummySegFormer(),\n",
        "    \"UW-SegFormer-B0 (No enhancement)\": DummySegFormer(),\n",
        "    \"ResNet-50 DeepLab v3+ (FP16)\": models.segmentation.deeplabv3_resnet50(pretrained=False)\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Metrics Calculation Functions\n",
        "# ------------------------------\n",
        "def compute_miou(pred, target):\n",
        "    pred = pred > 0.5\n",
        "    target = target > 0.5\n",
        "    intersection = (pred & target).sum().float()\n",
        "    union = (pred | target).sum().float()\n",
        "    return (intersection / union).item()\n",
        "\n",
        "def measure_latency(model, device, input_size=(1, 3, 256, 256), runs=50):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(input_size).to(device)\n",
        "    torch.cuda.synchronize()\n",
        "    start = time.time()\n",
        "    for _ in range(runs):\n",
        "        _ = model(dummy_input)\n",
        "    torch.cuda.synchronize()\n",
        "    end = time.time()\n",
        "    avg_latency = (end - start) / runs\n",
        "    return avg_latency\n",
        "\n",
        "def measure_gpu_power():\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    if not gpus:\n",
        "        return None, None\n",
        "    gpu = gpus[0]\n",
        "    return gpu.load * 100, gpu.powerUsage\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Evaluation Loop\n",
        "# ------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "results = []\n",
        "for model_name, model in models_dict.items():\n",
        "    print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "    # Params & GFLOPs\n",
        "    with torch.cuda.device(0):\n",
        "        macs, params = get_model_complexity_info(model, (3, 256, 256), as_strings=False, print_per_layer_stat=False)\n",
        "\n",
        "    # Latency & FPS\n",
        "    latency = measure_latency(model, device)\n",
        "    fps = 1 / latency\n",
        "\n",
        "    # GPU utilization & Power\n",
        "    gpu_util, power = measure_gpu_power()\n",
        "\n",
        "    # mIoU on SUIM & UIEB\n",
        "    miou_suim = np.mean([compute_miou(model(img.unsqueeze(0).to(device)), mask.unsqueeze(0).to(device))\n",
        "                         for img, mask in suim_loader])\n",
        "    miou_uieb = np.mean([compute_miou(model(img.unsqueeze(0).to(device)), mask.unsqueeze(0).to(device))\n",
        "                         for img, mask in uieb_loader])\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Params(M)\": round(params / 1e6, 2),\n",
        "        \"GFLOPs\": round(macs / 1e9, 2),\n",
        "        \"Latency(s)\": round(latency, 4),\n",
        "        \"FPS\": round(fps, 2),\n",
        "        \"GPU Util(%)\": round(gpu_util, 2) if gpu_util else None,\n",
        "        \"Power(W)\": round(power, 2) if power else None,\n",
        "        \"mIoU (SUIM)\": round(miou_suim, 4),\n",
        "        \"mIoU (UIEB)\": round(miou_uieb, 4)\n",
        "    })\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Print Results\n",
        "# ------------------------------\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(results)\n",
        "print(\"\\nFinal Evaluation Results:\")\n",
        "print(df)\n"
      ]
    }
  ]
}