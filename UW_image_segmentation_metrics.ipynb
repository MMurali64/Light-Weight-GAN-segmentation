{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVCLWAGC4Nxr"
      },
      "outputs": [],
      "source": [
        "!pip install gdown segmentation-models-pytorch torch torchvision opencv-python scikit-learn\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import gdown\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ======================\n",
        "# User Input Links\n",
        "# ======================\n",
        "suim_link = input(\"Enter Google Drive link for SUIM dataset: \").strip()\n",
        "uieb_link = input(\"Enter Google Drive link for UIEB dataset: \").strip()\n",
        "\n",
        "# ======================\n",
        "# Download Function\n",
        "# ======================\n",
        "def download_and_extract(gdrive_link, output_dir):\n",
        "    if \"id=\" in gdrive_link:\n",
        "        file_id = gdrive_link.split(\"id=\")[1]\n",
        "    elif \"/d/\" in gdrive_link:\n",
        "        file_id = gdrive_link.split(\"/d/\")[1].split(\"/\")[0]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid Google Drive link format.\")\n",
        "\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", \"temp.zip\", quiet=False)\n",
        "    with zipfile.ZipFile(\"temp.zip\", 'r') as zip_ref:\n",
        "        zip_ref.extractall(output_dir)\n",
        "    os.remove(\"temp.zip\")\n",
        "    print(f\"Extracted to: {output_dir}\")\n",
        "\n",
        "# Download datasets\n",
        "download_and_extract(suim_link, \"SUIM\")\n",
        "download_and_extract(uieb_link, \"UIEB\")\n",
        "\n",
        "# ======================\n",
        "# Metric Functions\n",
        "# ======================\n",
        "def pixel_accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def mean_iou(y_true, y_pred, num_classes):\n",
        "    ious = []\n",
        "    for cls in range(num_classes):\n",
        "        intersection = np.logical_and(y_pred == cls, y_true == cls).sum()\n",
        "        union = np.logical_or(y_pred == cls, y_true == cls).sum()\n",
        "        if union > 0:\n",
        "            ious.append(intersection / union)\n",
        "    return np.mean(ious)\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, num_classes):\n",
        "    dice_scores = []\n",
        "    for cls in range(num_classes):\n",
        "        intersection = np.logical_and(y_pred == cls, y_true == cls).sum()\n",
        "        total = (y_pred == cls).sum() + (y_true == cls).sum()\n",
        "        if total > 0:\n",
        "            dice_scores.append(2 * intersection / total)\n",
        "    return np.mean(dice_scores)\n",
        "\n",
        "def mean_pixel_accuracy(y_true, y_pred, num_classes):\n",
        "    acc_per_class = []\n",
        "    for cls in range(num_classes):\n",
        "        cls_pixels = (y_true == cls).sum()\n",
        "        if cls_pixels > 0:\n",
        "            acc_per_class.append(((y_pred == cls) & (y_true == cls)).sum() / cls_pixels)\n",
        "    return np.mean(acc_per_class)\n",
        "\n",
        "# ======================\n",
        "# Model Evaluation\n",
        "# ======================\n",
        "def evaluate_dataset(dataset_path, model, device, num_classes):\n",
        "    image_dir = os.path.join(dataset_path, \"images\")\n",
        "    mask_dir = os.path.join(dataset_path, \"masks\")\n",
        "\n",
        "    pa_list, miou_list, dice_list, mpa_list = [], [], [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for fname in os.listdir(image_dir):\n",
        "            img_path = os.path.join(image_dir, fname)\n",
        "            mask_path = os.path.join(mask_dir, fname)\n",
        "\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            mask_gt = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            img_tensor = torch.tensor(img.transpose(2,0,1) / 255.0, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "            pred_mask = model(img_tensor)\n",
        "            pred_mask = torch.argmax(pred_mask.squeeze(), dim=0).cpu().numpy()\n",
        "\n",
        "            pa_list.append(pixel_accuracy(mask_gt, pred_mask))\n",
        "            miou_list.append(mean_iou(mask_gt, pred_mask, num_classes))\n",
        "            dice_list.append(dice_coefficient(mask_gt, pred_mask, num_classes))\n",
        "            mpa_list.append(mean_pixel_accuracy(mask_gt, pred_mask, num_classes))\n",
        "\n",
        "    return np.mean(pa_list), np.mean(miou_list), np.mean(dice_list), np.mean(mpa_list)\n",
        "\n",
        "# ======================\n",
        "# Main Execution\n",
        "# ======================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "NUM_CLASSES = 8  # Adjust according to dataset\n",
        "\n",
        "# Define models (random init here; load trained weights in real case)\n",
        "models = {\n",
        "    \"UNet\": smp.Unet(encoder_name=\"resnet34\", classes=NUM_CLASSES, encoder_weights=None).to(device),\n",
        "    \"PSPNet\": smp.PSPNet(encoder_name=\"resnet34\", classes=NUM_CLASSES, encoder_weights=None).to(device),\n",
        "    \"UNet++\": smp.UnetPlusPlus(encoder_name=\"resnet34\", classes=NUM_CLASSES, encoder_weights=None).to(device),\n",
        "    \"DeepLabv3+\": smp.DeepLabV3Plus(encoder_name=\"resnet34\", classes=NUM_CLASSES, encoder_weights=None).to(device)\n",
        "}\n",
        "\n",
        "# Evaluate SUIM\n",
        "print(\"\\n=== SUIM Dataset Evaluation ===\")\n",
        "for name, model in models.items():\n",
        "    pa, miou, dice, mpa = evaluate_dataset(\"SUIM\", model, device, NUM_CLASSES)\n",
        "    print(f\"{name}: Pixel Acc={pa:.4f}, mIoU={miou:.4f}, Dice={dice:.4f}, mPA={mpa:.4f}\")\n",
        "\n",
        "# Evaluate UIEB\n",
        "print(\"\\n=== UIEB Dataset Evaluation ===\")\n",
        "for name, model in models.items():\n",
        "    pa, miou, dice, mpa = evaluate_dataset(\"UIEB\", model, device, NUM_CLASSES)\n",
        "    print(f\"{name}: Pixel Acc={pa:.4f}, mIoU={miou:.4f}, Dice={dice:.4f}, mPA={mpa:.4f}\")\n"
      ]
    }
  ]
}